{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import codecs\n",
    "\n",
    "# объявим где хранятся исходные данные\n",
    "PATH_TRAIN = 'train.csv'\n",
    "PATH_TEST = 'test.csv'\n",
    "\n",
    "# объявим куда сохраним результат\n",
    "PATH_PRED = 'pred.csv'\n",
    "\n",
    "\n",
    "## Из тренировочного набора собираем статистику о встречаемости слов\n",
    "\n",
    "# создаем словарь для хранения статистики\n",
    "word_stat_dict = {}\n",
    "\n",
    "# открываем файл на чтение в режиме текста\n",
    "fl = codecs.open(PATH_TRAIN, 'r', encoding='utf-8')\n",
    "\n",
    "# считываем первую строчку - заголовок (она нам не нужна)\n",
    "fl.readline()\n",
    "\n",
    "# в цикле читаем строчки из файла\n",
    "for line in fl:\n",
    "    # разбиваем строчку на три строковые переменные\n",
    "    Id, Sample, Prediction = line.strip().split(',')\n",
    "    # строковая переменная Prediction - содержит в себе словосочетание из 2 слов, разделим их\n",
    "    _, word2 = Prediction.split(' ')\n",
    "    # возьмем в качестве ключа 2 первые буквы, т.к. их наличие гарантировано\n",
    "    _, key = Sample.split(' ')\n",
    "    # если такого ключа еще нет в словаре, то создадим пустой словарь для этого ключа\n",
    "    if key not in word_stat_dict:\n",
    "        word_stat_dict[key] = {}\n",
    "    # если текущее слово еще не встречалось, то добавим его в словарь и установим счетчик этого слова в 0\n",
    "    if word2 not in word_stat_dict[key]:\n",
    "        word_stat_dict[key][word2] = 0\n",
    "    # увеличим значение счетчика по текущему слову на 1\n",
    "    word_stat_dict[key][word2] += 1\n",
    "\n",
    "# закрываем файл\n",
    "fl.close()\n",
    "\n",
    "## Строим модель\n",
    "\n",
    "# создаем словарь для хранения статистики\n",
    "most_freq_dict = {}\n",
    "\n",
    "# проходим по словарю word_stat_dict\n",
    "for key in word_stat_dict:\n",
    "    # для каждого ключа получаем наиболее часто встречающееся (наиболее вероятное) слово и записываем его в словарь most_freq_dict\n",
    "    most_freq_dict[key] = max(word_stat_dict[key], key=word_stat_dict[key].get)\n",
    "\n",
    "\n",
    "## Выполняем предсказание\n",
    "\n",
    "# открываем файл на чтение в режиме текста\n",
    "fl = open(PATH_TEST, 'r', encoding='utf-8')\n",
    "\n",
    "# считываем первую строчку - заголовок (она нам не нужна)\n",
    "fl.readline()\n",
    "\n",
    "# открываем файл на запись в режиме текста\n",
    "out_fl = open(PATH_PRED, 'w', encoding='utf-8')\n",
    "\n",
    "# записываем заголовок таблицы\n",
    "out_fl.write('Id,Prediction\\n')\n",
    "\n",
    "# в цикле читаем строчки из тестового файла\n",
    "for line in fl:\n",
    "    # разбиваем строчку на две строковые переменные\n",
    "    Id, Sample = line.strip().split(',')\n",
    "    # строковая переменная Sample содержит в себе полностью первое слово и кусок второго слова, разделим их\n",
    "    word1, word2_chunk = Sample.split(' ')\n",
    "    # вычислим ключ для заданного фрагмента второго слова\n",
    "    k=0\n",
    "    for i in range(len(word2_chunk),1,-1):\n",
    "        if word2_chunk[:i] in most_freq_dict:\n",
    "            out_fl.write('%s,%s %s\\n' % (Id, word1, most_freq_dict[word2_chunk[:i]]) )\n",
    "            k=1\n",
    "            break\n",
    "    if k==0:\n",
    "        out_fl.write('%s,%s\\n' % (Id, 'что она') )\n",
    "    \n",
    "    \n",
    "# закрываем файлы\n",
    "fl.close()\n",
    "out_fl.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
